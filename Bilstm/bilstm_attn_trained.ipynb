{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>20 per txn</td>\n",
       "      <td>0.134826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil Charges</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil charges upto 5 transactions; thereafter Rs...</td>\n",
       "      <td>0.355285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs.25 per transaction</td>\n",
       "      <td>0.641480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs. 750</td>\n",
       "      <td>0.803360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  ace savings account platinum debit card annual...   \n",
       "1  ace savings account platinum debit card annual...   \n",
       "2  ace savings account platinum debit card annual...   \n",
       "3  ace savings account platinum debit card annual...   \n",
       "4  ace savings account platinum debit card annual...   \n",
       "\n",
       "                                              Answer     Score  \n",
       "0                                         20 per txn  0.134826  \n",
       "1                                        Nil Charges  1.000000  \n",
       "2  Nil charges upto 5 transactions; thereafter Rs...  0.355285  \n",
       "3                              Rs.25 per transaction  0.641480  \n",
       "4                                            Rs. 750  0.803360  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_faq.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9972,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = list(df['Query'])\n",
    "answers = list(df['Answer'])\n",
    "prob = np.array(df['Score'], dtype=float)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9972\n",
      "9972\n",
      "Unique questions: 545\n",
      "Unique answers: 18\n"
     ]
    }
   ],
   "source": [
    "print(len(queries))\n",
    "print(len(answers))\n",
    "print('Unique questions:',len(set(queries)))\n",
    "print('Unique answers:',len(set(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 40000\n",
    "vocab_size=2000\n",
    "seq_maxlen=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 5, 4, 84, 1, 2, 11, 3]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 58  5  4 84  1  2 11  3]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(queries+answers)\n",
    "\n",
    "queries_tf = word_tokenizer.texts_to_sequences(queries)\n",
    "answers_tf = word_tokenizer.texts_to_sequences(answers)\n",
    "print(queries_tf[52])\n",
    "\n",
    "queries_tf = sequence.pad_sequences(queries_tf, maxlen=seq_maxlen)\n",
    "answers_tf = sequence.pad_sequences(answers_tf, maxlen=seq_maxlen)\n",
    "print(queries_tf[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2VEC_EMBED_SIZE = 100\n",
    "QA_EMBED_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = 'glove.6B/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((vocab_size, WORD2VEC_EMBED_SIZE))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if (embedding_vector is not None) and i <= vocab_size:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "print(len(weights_matrix[2,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6292e-01 -3.1798e-01  4.2328e-01 -8.6767e-01  4.5101e-01  5.7857e-01\n",
      "  2.6645e-02 -1.2648e-01  3.3465e-01 -4.2047e-02 -4.0596e-02  1.6478e-01\n",
      " -6.7344e-01 -3.3751e-01  3.5913e-01  5.7383e-01  8.4620e-01  3.6374e-01\n",
      "  3.0630e-01 -6.8050e-02 -6.7610e-01 -1.9147e-01 -1.4594e-01  3.2621e-03\n",
      "  6.6949e-01 -3.3588e-01  1.7868e-01 -3.9360e-01  1.7700e-01 -3.3642e-01\n",
      "  1.9288e-01  1.0030e+00 -2.1794e-01  2.4271e-01  1.0935e+00 -1.0303e-01\n",
      " -7.9197e-01 -1.3506e-01  1.2156e-01 -9.8377e-01  1.0300e+00 -1.0242e+00\n",
      "  6.0269e-01 -1.5986e-01 -2.6773e-01 -5.5630e-01  2.5834e-01 -8.5021e-02\n",
      " -1.5221e-01 -3.3717e-01  2.6358e-02  2.3171e-01 -1.8056e-01  5.7107e-01\n",
      "  3.8556e-01 -1.5732e+00 -1.4902e-01  3.7826e-02  1.8485e+00  7.0210e-01\n",
      " -1.1697e-01  7.7822e-02  7.4620e-02  9.9570e-02 -2.1427e-01 -6.0061e-01\n",
      "  9.4903e-02  8.0589e-01  5.5333e-01 -3.1359e-01 -9.0991e-01  5.3645e-02\n",
      " -1.4494e-01 -4.8532e-01  1.0335e-01  1.2182e+00 -2.2199e-01 -1.4934e-02\n",
      " -1.1355e+00  3.2790e-01  1.1733e+00 -5.2838e-01 -6.6953e-01 -6.2109e-01\n",
      " -1.3660e+00 -4.4052e-01 -2.9538e-01 -7.1655e-01  5.9920e-01 -3.4550e-04\n",
      " -8.2363e-01  9.3572e-01  6.2134e-01 -2.6649e-01  9.9595e-02 -1.1545e-01\n",
      "  6.0000e-01  7.2834e-02  6.6487e-01 -6.4510e-01]\n"
     ]
    }
   ],
   "source": [
    "print(weights_matrix[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NBR_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:21: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:27: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "qenc = Sequential()\n",
    "qenc.add(Embedding(output_dim=WORD2VEC_EMBED_SIZE, \n",
    "                   input_dim=vocab_size,\n",
    "                   input_length=seq_maxlen,\n",
    "                   weights=[weights_matrix]))\n",
    "qenc.add(Bidirectional(LSTM(QA_EMBED_SIZE, return_sequences=True), \n",
    "                       merge_mode=\"sum\"))\n",
    "qenc.add(Dropout(0.3))\n",
    "\n",
    "aenc = Sequential()\n",
    "aenc.add(Embedding(output_dim=WORD2VEC_EMBED_SIZE, input_dim=vocab_size,\n",
    "                   input_length=seq_maxlen,\n",
    "                   weights=[weights_matrix]))\n",
    "aenc.add(Bidirectional(LSTM(QA_EMBED_SIZE, return_sequences=True),\n",
    "                       merge_mode=\"sum\"))\n",
    "aenc.add(Dropout(0.3))\n",
    "\n",
    "# attention model\n",
    "attn = Sequential()\n",
    "attn.add(Merge([qenc, aenc], mode=\"dot\", dot_axes=[1, 1]))\n",
    "attn.add(Flatten())\n",
    "attn.add(Dense((seq_maxlen * QA_EMBED_SIZE)))\n",
    "attn.add(Reshape((seq_maxlen, QA_EMBED_SIZE)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([qenc, attn], mode=\"sum\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_4 (Merge)              (None, 35, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2241      \n",
      "=================================================================\n",
      "Total params: 9,748,481\n",
      "Trainable params: 9,748,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot arch\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='bilstm_attn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "prob=to_categorical(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, sample, seed\n",
    "\n",
    "seed(123)\n",
    "split = 0.3\n",
    "idx = sample(range(queries_tf.shape[0]), queries_tf.shape[0])\n",
    "#shuffle\n",
    "queries_tf = queries_tf[idx, :]\n",
    "answers_tf = answers_tf[idx, :]\n",
    "prob = prob[idx, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9972, 35)\n",
      "(9972, 35)\n",
      "(9972, 2)\n"
     ]
    }
   ],
   "source": [
    "print(queries_tf.shape)\n",
    "print(answers_tf.shape)\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('bilstm_atten_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6980 samples, validate on 2992 samples\n",
      "Epoch 1/20\n",
      "6980/6980 [==============================] - 64s 9ms/step - loss: 0.9232 - acc: 0.9384 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 2/20\n",
      "6980/6980 [==============================] - 63s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 3/20\n",
      "6980/6980 [==============================] - 68s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 4/20\n",
      "6980/6980 [==============================] - 61s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 5/20\n",
      "6980/6980 [==============================] - 60s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 6/20\n",
      "6980/6980 [==============================] - 61s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 7/20\n",
      "6980/6980 [==============================] - 63s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 8/20\n",
      "6980/6980 [==============================] - 64s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 9/20\n",
      "6980/6980 [==============================] - 65s 9ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 10/20\n",
      "6980/6980 [==============================] - 59s 8ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 11/20\n",
      "6980/6980 [==============================] - 54s 8ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 12/20\n",
      "6980/6980 [==============================] - 53s 8ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 13/20\n",
      "6980/6980 [==============================] - 53s 8ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 14/20\n",
      "6980/6980 [==============================] - 67s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 15/20\n",
      "6980/6980 [==============================] - 76s 11ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 16/20\n",
      "6980/6980 [==============================] - 70s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 17/20\n",
      "6980/6980 [==============================] - 69s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 18/20\n",
      "6980/6980 [==============================] - 67s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 19/20\n",
      "6980/6980 [==============================] - 83s 12ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n",
      "Epoch 20/20\n",
      "6980/6980 [==============================] - 69s 10ms/step - loss: 0.9167 - acc: 0.9431 - val_loss: 0.8458 - val_acc: 0.9475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1303b8198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([queries_tf, answers_tf], \n",
    "          prob,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NBR_EPOCHS,\n",
    "          validation_split=split, \n",
    "          callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
