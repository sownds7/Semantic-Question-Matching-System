{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>20 per txn</td>\n",
       "      <td>0.231745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil Charges</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil charges upto 5 transactions; thereafter Rs...</td>\n",
       "      <td>0.464369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs.25 per transaction</td>\n",
       "      <td>0.309488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs. 750</td>\n",
       "      <td>0.797618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  ace savings account platinum debit card annual...   \n",
       "1  ace savings account platinum debit card annual...   \n",
       "2  ace savings account platinum debit card annual...   \n",
       "3  ace savings account platinum debit card annual...   \n",
       "4  ace savings account platinum debit card annual...   \n",
       "\n",
       "                                              Answer     Score  \n",
       "0                                         20 per txn  0.231745  \n",
       "1                                        Nil Charges  1.000000  \n",
       "2  Nil charges upto 5 transactions; thereafter Rs...  0.464369  \n",
       "3                              Rs.25 per transaction  0.309488  \n",
       "4                                            Rs. 750  0.797618  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_faq_abs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries = list(df['Query'])\n",
    "answers = list(df['Answer'])\n",
    "prob = np.array(df['Score'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9972\n",
      "9972\n",
      "(9972,)\n",
      "Unique questions: 545\n",
      "Unique answers: 18\n"
     ]
    }
   ],
   "source": [
    "print(len(queries))\n",
    "print(len(answers))\n",
    "print(prob.shape)\n",
    "print('Unique questions:',len(set(queries)))\n",
    "print('Unique answers:',len(set(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 40000\n",
    "vocab_size=2000\n",
    "seq_maxlen=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 5, 4, 84, 1, 2, 11, 3]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 58  5  4 84  1  2 11  3]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(queries+answers)\n",
    "\n",
    "queries_tf = word_tokenizer.texts_to_sequences(queries)\n",
    "answers_tf = word_tokenizer.texts_to_sequences(answers)\n",
    "print(queries_tf[52])\n",
    "\n",
    "queries_tf = sequence.pad_sequences(queries_tf, maxlen=seq_maxlen)\n",
    "answers_tf = sequence.pad_sequences(answers_tf, maxlen=seq_maxlen)\n",
    "print(queries_tf[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2VEC_EMBED_SIZE = 100\n",
    "QA_EMBED_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = 'glove.6B/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6292e-01 -3.1798e-01  4.2328e-01 -8.6767e-01  4.5101e-01  5.7857e-01\n",
      "  2.6645e-02 -1.2648e-01  3.3465e-01 -4.2047e-02 -4.0596e-02  1.6478e-01\n",
      " -6.7344e-01 -3.3751e-01  3.5913e-01  5.7383e-01  8.4620e-01  3.6374e-01\n",
      "  3.0630e-01 -6.8050e-02 -6.7610e-01 -1.9147e-01 -1.4594e-01  3.2621e-03\n",
      "  6.6949e-01 -3.3588e-01  1.7868e-01 -3.9360e-01  1.7700e-01 -3.3642e-01\n",
      "  1.9288e-01  1.0030e+00 -2.1794e-01  2.4271e-01  1.0935e+00 -1.0303e-01\n",
      " -7.9197e-01 -1.3506e-01  1.2156e-01 -9.8377e-01  1.0300e+00 -1.0242e+00\n",
      "  6.0269e-01 -1.5986e-01 -2.6773e-01 -5.5630e-01  2.5834e-01 -8.5021e-02\n",
      " -1.5221e-01 -3.3717e-01  2.6358e-02  2.3171e-01 -1.8056e-01  5.7107e-01\n",
      "  3.8556e-01 -1.5732e+00 -1.4902e-01  3.7826e-02  1.8485e+00  7.0210e-01\n",
      " -1.1697e-01  7.7822e-02  7.4620e-02  9.9570e-02 -2.1427e-01 -6.0061e-01\n",
      "  9.4903e-02  8.0589e-01  5.5333e-01 -3.1359e-01 -9.0991e-01  5.3645e-02\n",
      " -1.4494e-01 -4.8532e-01  1.0335e-01  1.2182e+00 -2.2199e-01 -1.4934e-02\n",
      " -1.1355e+00  3.2790e-01  1.1733e+00 -5.2838e-01 -6.6953e-01 -6.2109e-01\n",
      " -1.3660e+00 -4.4052e-01 -2.9538e-01 -7.1655e-01  5.9920e-01 -3.4550e-04\n",
      " -8.2363e-01  9.3572e-01  6.2134e-01 -2.6649e-01  9.9595e-02 -1.1545e-01\n",
      "  6.0000e-01  7.2834e-02  6.6487e-01 -6.4510e-01]\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((vocab_size, WORD2VEC_EMBED_SIZE))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if (embedding_vector is not None) and i <= vocab_size:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "#index 0 vector should be all zeroes, index 1 vector should be the same one as above\n",
    "print(weights_matrix[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NBR_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:25: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "# output: (None, QA_EMBED_SIZE, seq_maxlen)\n",
    "qin = Input(shape=(seq_maxlen,), dtype=\"int32\")\n",
    "qenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim=WORD2VEC_EMBED_SIZE,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[weights_matrix])(qin)\n",
    "qenc = LSTM(QA_EMBED_SIZE, return_sequences=True)(qenc)\n",
    "qenc = Dropout(0.3)(qenc)\n",
    "\n",
    "# output: (None, QA_EMBED_SIZE, seq_maxlen)\n",
    "ain = Input(shape=(seq_maxlen,), dtype=\"int32\")\n",
    "aenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim=WORD2VEC_EMBED_SIZE,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[weights_matrix])(ain)\n",
    "aenc = LSTM(QA_EMBED_SIZE, return_sequences=True)(aenc)\n",
    "aenc = Dropout(0.3)(aenc)\n",
    "\n",
    "# attention model\n",
    "attn = merge([qenc, aenc], mode=\"dot\", dot_axes=[1, 1])\n",
    "attn = Flatten()(attn)\n",
    "attn = Dense(seq_maxlen * QA_EMBED_SIZE)(attn)\n",
    "attn = Reshape((seq_maxlen, QA_EMBED_SIZE))(attn)\n",
    "\n",
    "qenc_attn = merge([qenc, attn], mode=\"sum\")\n",
    "qenc_attn = Flatten()(qenc_attn)\n",
    "\n",
    "output = Dense(1, activation=\"softmax\")(qenc_attn)\n",
    "\n",
    "model = Model(input=[qin, ain], output=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 35, 100)      200000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 35, 100)      200000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 35, 64)       42240       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 35, 64)       42240       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 64)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 64)       0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 64, 64)       0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2240)         9177280     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 35, 64)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 35, 64)       0           dropout_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2240)         0           merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2241        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,664,001\n",
      "Trainable params: 9,664,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Compiling model...\")\n",
    "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='lstm_attn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils.np_utils import to_categorical\n",
    "#prob=to_categorical(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prob = np.array(df['Score'], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9972, 35)\n",
      "(9972, 35)\n",
      "(9972,)\n"
     ]
    }
   ],
   "source": [
    "from random import random, sample, seed\n",
    "\n",
    "seed(123)\n",
    "split = 0.3\n",
    "idx = sample(range(queries_tf.shape[0]), queries_tf.shape[0])\n",
    "\n",
    "#shuffle\n",
    "queries_tf = queries_tf[idx, :]\n",
    "answers_tf = answers_tf[idx, :]\n",
    "prob = prob[idx, ]\n",
    "\n",
    "print(queries_tf.shape)\n",
    "print(answers_tf.shape)\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('lstm_attn_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6980 samples, validate on 2992 samples\n",
      "Epoch 1/10\n",
      "6980/6980 [==============================] - 24s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 2/10\n",
      "6980/6980 [==============================] - 22s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 3/10\n",
      "6980/6980 [==============================] - 22s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 4/10\n",
      "6980/6980 [==============================] - 23s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 5/10\n",
      "6980/6980 [==============================] - 23s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 6/10\n",
      "6980/6980 [==============================] - 21s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 7/10\n",
      "6980/6980 [==============================] - 20s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 8/10\n",
      "6980/6980 [==============================] - 20s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 9/10\n",
      "6980/6980 [==============================] - 20s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 10/10\n",
      "6980/6980 [==============================] - 20s 3ms/step - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118423748>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([queries_tf, answers_tf], \n",
    "          prob,\n",
    "          batch_size=100,\n",
    "          epochs=10,\n",
    "          validation_split=split, \n",
    "          #callbacks=[csv_logger]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
