{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from random import random, sample, seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>20 per txn</td>\n",
       "      <td>0.134826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil Charges</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Nil charges upto 5 transactions; thereafter Rs...</td>\n",
       "      <td>0.355285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs.25 per transaction</td>\n",
       "      <td>0.641480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs. 750</td>\n",
       "      <td>0.803360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs. 250</td>\n",
       "      <td>0.851215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>Rs. 500</td>\n",
       "      <td>0.061913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>All txns are Chargeable</td>\n",
       "      <td>-0.033971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>8.50 per txn (All the charges are exclusive of...</td>\n",
       "      <td>0.026407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ace savings account platinum debit card annual...</td>\n",
       "      <td>150 per txn</td>\n",
       "      <td>0.171966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  ace savings account platinum debit card annual...   \n",
       "1  ace savings account platinum debit card annual...   \n",
       "2  ace savings account platinum debit card annual...   \n",
       "3  ace savings account platinum debit card annual...   \n",
       "4  ace savings account platinum debit card annual...   \n",
       "5  ace savings account platinum debit card annual...   \n",
       "6  ace savings account platinum debit card annual...   \n",
       "7  ace savings account platinum debit card annual...   \n",
       "8  ace savings account platinum debit card annual...   \n",
       "9  ace savings account platinum debit card annual...   \n",
       "\n",
       "                                              Answer     Score  \n",
       "0                                         20 per txn  0.134826  \n",
       "1                                        Nil Charges  1.000000  \n",
       "2  Nil charges upto 5 transactions; thereafter Rs...  0.355285  \n",
       "3                              Rs.25 per transaction  0.641480  \n",
       "4                                            Rs. 750  0.803360  \n",
       "5                                           Rs. 250   0.851215  \n",
       "6                                            Rs. 500  0.061913  \n",
       "7                            All txns are Chargeable -0.033971  \n",
       "8  8.50 per txn (All the charges are exclusive of...  0.026407  \n",
       "9                                        150 per txn  0.171966  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_faq.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9972,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = list(df['Query'])\n",
    "answers = list(df['Answer'])\n",
    "prob = np.array(df['Score'], dtype=float)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9972\n",
      "9972\n",
      "Unique questions: 545\n",
      "Unique answers: 18\n"
     ]
    }
   ],
   "source": [
    "print(len(queries))\n",
    "print(len(answers))\n",
    "print('Unique questions:',len(set(queries)))\n",
    "print('Unique answers:',len(set(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 40000\n",
    "vocab_size=2000\n",
    "seq_maxlen=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 5, 4, 84, 1, 2, 11, 3]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 58  5  4 84  1  2 11  3]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(queries+answers)\n",
    "\n",
    "queries_tf = word_tokenizer.texts_to_sequences(queries)\n",
    "answers_tf = word_tokenizer.texts_to_sequences(answers)\n",
    "print(queries_tf[52])\n",
    "\n",
    "queries_tf = sequence.pad_sequences(queries_tf, maxlen=seq_maxlen)\n",
    "answers_tf = sequence.pad_sequences(answers_tf, maxlen=seq_maxlen)\n",
    "print(queries_tf[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2VEC_EMBED_SIZE = 100\n",
    "QA_EMBED_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_path = 'glove.6B/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vectors = {}\n",
    "\n",
    "with open(embeddings_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line.strip().split(\" \")\n",
    "        vec = np.array(line_split[1:], dtype=float)\n",
    "        word = line_split[0]\n",
    "        embedding_vectors[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6292e-01 -3.1798e-01  4.2328e-01 -8.6767e-01  4.5101e-01  5.7857e-01\n",
      "  2.6645e-02 -1.2648e-01  3.3465e-01 -4.2047e-02 -4.0596e-02  1.6478e-01\n",
      " -6.7344e-01 -3.3751e-01  3.5913e-01  5.7383e-01  8.4620e-01  3.6374e-01\n",
      "  3.0630e-01 -6.8050e-02 -6.7610e-01 -1.9147e-01 -1.4594e-01  3.2621e-03\n",
      "  6.6949e-01 -3.3588e-01  1.7868e-01 -3.9360e-01  1.7700e-01 -3.3642e-01\n",
      "  1.9288e-01  1.0030e+00 -2.1794e-01  2.4271e-01  1.0935e+00 -1.0303e-01\n",
      " -7.9197e-01 -1.3506e-01  1.2156e-01 -9.8377e-01  1.0300e+00 -1.0242e+00\n",
      "  6.0269e-01 -1.5986e-01 -2.6773e-01 -5.5630e-01  2.5834e-01 -8.5021e-02\n",
      " -1.5221e-01 -3.3717e-01  2.6358e-02  2.3171e-01 -1.8056e-01  5.7107e-01\n",
      "  3.8556e-01 -1.5732e+00 -1.4902e-01  3.7826e-02  1.8485e+00  7.0210e-01\n",
      " -1.1697e-01  7.7822e-02  7.4620e-02  9.9570e-02 -2.1427e-01 -6.0061e-01\n",
      "  9.4903e-02  8.0589e-01  5.5333e-01 -3.1359e-01 -9.0991e-01  5.3645e-02\n",
      " -1.4494e-01 -4.8532e-01  1.0335e-01  1.2182e+00 -2.2199e-01 -1.4934e-02\n",
      " -1.1355e+00  3.2790e-01  1.1733e+00 -5.2838e-01 -6.6953e-01 -6.2109e-01\n",
      " -1.3660e+00 -4.4052e-01 -2.9538e-01 -7.1655e-01  5.9920e-01 -3.4550e-04\n",
      " -8.2363e-01  9.3572e-01  6.2134e-01 -2.6649e-01  9.9595e-02 -1.1545e-01\n",
      "  6.0000e-01  7.2834e-02  6.6487e-01 -6.4510e-01]\n"
     ]
    }
   ],
   "source": [
    "weights_matrix = np.zeros((vocab_size, WORD2VEC_EMBED_SIZE))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    embedding_vector = embedding_vectors.get(word)\n",
    "    if (embedding_vector is not None) and i <= vocab_size:\n",
    "        weights_matrix[i] = embedding_vector\n",
    "\n",
    "#index 0 vector should be all zeroes, index 1 vector should be the same one as above\n",
    "print(weights_matrix[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NBR_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:25: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "# output: (None, QA_EMBED_SIZE, seq_maxlen)\n",
    "qin = Input(shape=(seq_maxlen,), dtype=\"int32\")\n",
    "qenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim=WORD2VEC_EMBED_SIZE,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[weights_matrix])(qin)\n",
    "qenc = LSTM(QA_EMBED_SIZE, return_sequences=True)(qenc)\n",
    "qenc = Dropout(0.3)(qenc)\n",
    "\n",
    "# output: (None, QA_EMBED_SIZE, seq_maxlen)\n",
    "ain = Input(shape=(seq_maxlen,), dtype=\"int32\")\n",
    "aenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim=WORD2VEC_EMBED_SIZE,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[weights_matrix])(ain)\n",
    "aenc = LSTM(QA_EMBED_SIZE, return_sequences=True)(aenc)\n",
    "aenc = Dropout(0.3)(aenc)\n",
    "\n",
    "# attention model\n",
    "attn = merge([qenc, aenc], mode=\"dot\", dot_axes=[1, 1])\n",
    "attn = Flatten()(attn)\n",
    "attn = Dense(seq_maxlen * QA_EMBED_SIZE)(attn)\n",
    "attn = Reshape((seq_maxlen, QA_EMBED_SIZE))(attn)\n",
    "\n",
    "qenc_attn = merge([qenc, attn], mode=\"sum\")\n",
    "qenc_attn = Flatten()(qenc_attn)\n",
    "\n",
    "output = Dense(2, activation=\"softmax\")(qenc_attn)\n",
    "\n",
    "model = Model(input=[qin, ain], output=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 35, 100)      200000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 35, 100)      200000      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 35, 64)       42240       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 35, 64)       42240       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 64)       0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 35, 64)       0           lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 64, 64)       0           dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4096)         0           merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2240)         9177280     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 35, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_4 (Merge)                 (None, 35, 64)       0           dropout_3[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2240)         0           merge_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            4482        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,666,242\n",
      "Trainable params: 9,666,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Compiling model...\")\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='lstm_attn.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "prob=to_categorical(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, sample, seed\n",
    "\n",
    "seed(123)\n",
    "split = 0.3\n",
    "idx = sample(range(queries_tf.shape[0]), queries_tf.shape[0])\n",
    "\n",
    "#shuffle\n",
    "queries_tf = queries_tf[idx, :]\n",
    "answers_tf = answers_tf[idx, :]\n",
    "prob = prob[idx, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9972, 35)\n",
      "(9972, 35)\n",
      "(9972, 2)\n"
     ]
    }
   ],
   "source": [
    "print(queries_tf.shape)\n",
    "print(answers_tf.shape)\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('lstm_atten_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6980 samples, validate on 2992 samples\n",
      "Epoch 1/20\n",
      "6980/6980 [==============================] - 51s 7ms/step - loss: 0.2264 - acc: 0.9367 - val_loss: 0.1425 - val_acc: 0.9535\n",
      "Epoch 2/20\n",
      "6980/6980 [==============================] - 46s 7ms/step - loss: 0.1393 - acc: 0.9523 - val_loss: 0.1136 - val_acc: 0.9626\n",
      "Epoch 3/20\n",
      "6980/6980 [==============================] - 46s 7ms/step - loss: 0.1162 - acc: 0.9560 - val_loss: 0.0933 - val_acc: 0.9706\n",
      "Epoch 4/20\n",
      "6980/6980 [==============================] - 46s 7ms/step - loss: 0.0999 - acc: 0.9616 - val_loss: 0.0972 - val_acc: 0.9672\n",
      "Epoch 5/20\n",
      "6980/6980 [==============================] - 47s 7ms/step - loss: 0.0895 - acc: 0.9666 - val_loss: 0.0809 - val_acc: 0.9686\n",
      "Epoch 6/20\n",
      "6980/6980 [==============================] - 49s 7ms/step - loss: 0.0751 - acc: 0.9696 - val_loss: 0.0677 - val_acc: 0.9733\n",
      "Epoch 7/20\n",
      "6980/6980 [==============================] - 50s 7ms/step - loss: 0.0713 - acc: 0.9718 - val_loss: 0.0679 - val_acc: 0.9723\n",
      "Epoch 8/20\n",
      "6980/6980 [==============================] - 51s 7ms/step - loss: 0.0690 - acc: 0.9745 - val_loss: 0.0766 - val_acc: 0.9696\n",
      "Epoch 9/20\n",
      "6980/6980 [==============================] - 47s 7ms/step - loss: 0.0666 - acc: 0.9731 - val_loss: 0.0549 - val_acc: 0.9783\n",
      "Epoch 10/20\n",
      "6980/6980 [==============================] - 49s 7ms/step - loss: 0.0610 - acc: 0.9761 - val_loss: 0.0727 - val_acc: 0.9713\n",
      "Epoch 11/20\n",
      "6980/6980 [==============================] - 49s 7ms/step - loss: 0.0553 - acc: 0.9775 - val_loss: 0.0511 - val_acc: 0.9809\n",
      "Epoch 12/20\n",
      "6980/6980 [==============================] - 49s 7ms/step - loss: 0.0470 - acc: 0.9794 - val_loss: 0.0582 - val_acc: 0.9779\n",
      "Epoch 13/20\n",
      "6980/6980 [==============================] - 48s 7ms/step - loss: 0.0433 - acc: 0.9831 - val_loss: 0.0643 - val_acc: 0.9776\n",
      "Epoch 14/20\n",
      "6980/6980 [==============================] - 46s 7ms/step - loss: 0.0458 - acc: 0.9830 - val_loss: 0.0763 - val_acc: 0.9743\n",
      "Epoch 15/20\n",
      "6980/6980 [==============================] - 43s 6ms/step - loss: 0.0429 - acc: 0.9822 - val_loss: 0.0525 - val_acc: 0.9809\n",
      "Epoch 16/20\n",
      "6980/6980 [==============================] - 53s 8ms/step - loss: 0.0389 - acc: 0.9844 - val_loss: 0.0708 - val_acc: 0.9783\n",
      "Epoch 17/20\n",
      "6980/6980 [==============================] - 51s 7ms/step - loss: 0.0434 - acc: 0.9838 - val_loss: 0.0544 - val_acc: 0.9779\n",
      "Epoch 18/20\n",
      "6980/6980 [==============================] - 48s 7ms/step - loss: 0.0460 - acc: 0.9821 - val_loss: 0.0490 - val_acc: 0.9766\n",
      "Epoch 19/20\n",
      "6980/6980 [==============================] - 48s 7ms/step - loss: 0.0386 - acc: 0.9837 - val_loss: 0.0560 - val_acc: 0.9789\n",
      "Epoch 20/20\n",
      "6980/6980 [==============================] - 50s 7ms/step - loss: 0.0578 - acc: 0.9821 - val_loss: 0.0446 - val_acc: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1321a98d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([queries_tf, answers_tf], \n",
    "          prob,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NBR_EPOCHS,\n",
    "          validation_split=split, \n",
    "          callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
